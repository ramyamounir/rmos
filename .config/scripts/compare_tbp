#!/usr/bin/env python3

import argparse
import shutil
import subprocess
import sys
from pathlib import Path
from typing import Any, Dict, List, Set

import numpy as np
import pandas as pd
import yaml
from tabulate import tabulate

DEFAULT_CONFIG_PATH = Path.home() / ".config" / "tbp" / "compare_configs.yaml"


def get_current_branch() -> str:
    return (
        subprocess.check_output(["git", "rev-parse", "--abbrev-ref", "HEAD"])
        .decode()
        .strip()
    )


def ensure_clean_git_state():
    result = subprocess.run(
        ["git", "status", "--porcelain"],
        capture_output=True,
        text=True,
        check=True,
    )
    if result.stdout.strip():
        print("‚ùå Git working directory is not clean.")
        print("   Please commit or stash your changes before running this script.")
        sys.exit(1)


def run_benchmark(exp: str, cmd_template: str):
    print(f"‚ñ∂Ô∏è Running benchmark: {exp}")
    cmd = cmd_template.format(exp=exp)
    subprocess.run(cmd, shell=True, check=True)


def copy_result(
    exp: str, branch: str, result_dir: Path, result_filename: str, cache_dir: Path
):
    src = result_dir / exp / result_filename
    if not src.exists():
        print(f"‚ùå Result file not found: {src}")
        sys.exit(1)
    dest_dir = cache_dir / branch
    dest_dir.mkdir(parents=True, exist_ok=True)
    dest = dest_dir / f"{exp}.csv"
    shutil.copy(src, dest)
    print(f"‚úÖ Copied result to: {dest}")


def result_exists(exp: str, branch: str, cache_dir: Path) -> bool:
    return (cache_dir / branch / f"{exp}.csv").exists()


def compare_results(exp: str, branch1: str, branch2: str, cache_dir: Path) -> bool:
    file1 = cache_dir / branch1 / f"{exp}.csv"
    file2 = cache_dir / branch2 / f"{exp}.csv"

    if not file1.exists() or not file2.exists():
        print(f"‚ùå Missing result file(s) for comparison: {file1}, {file2}")
        return False

    df1 = pd.read_csv(file1)
    df2 = pd.read_csv(file2)

    mismatches = []

    all_cols = set(df1.columns).intersection(df2.columns)

    for col in sorted(all_cols):
        series1 = df1[col]
        series2 = df2[col]

        # Try to convert to numeric
        try:
            v1 = pd.to_numeric(series1, errors="raise")
            v2 = pd.to_numeric(series2, errors="raise")
            mean1 = np.mean(v1)
            mean2 = np.mean(v2)
            delta = mean2 - mean1
            if not np.isclose(mean1, mean2, atol=1e-6):
                mismatches.append(
                    [col, f"{mean1:.4f}", f"{mean2:.4f}", f"{delta:+.4f}"]
                )
        except Exception:
            # Fallback for non-numeric columns
            if not series1.equals(series2):
                mismatches.append([col, "MISMATCH", "MISMATCH", "MISMATCH"])

    if mismatches:
        print(f"\nüìå Differences found in experiment: {exp}")
        table = tabulate(
            mismatches,
            headers=["Metric", f"{branch1}", f"{branch2}", "Œî (delta)"],
            tablefmt="github",
        )
        print(table)
        return False
    else:
        print(f"[‚úÖ MATCH] {exp}")
        return True


def checkout_branch(branch: str):
    subprocess.run(["git", "checkout", branch], check=True)


def process_branch(
    branch: str,
    experiments: List[str],
    rerun_exps: Set[str],
    cache_dir: Path,
    result_dir: Path,
    result_filename: str,
    cmd_template: str,
):
    current = get_current_branch()
    if current != branch:
        print(f"üì¶ Checking out '{branch}'...")
        checkout_branch(branch)

    try:
        for exp in experiments:
            if result_exists(exp, branch, cache_dir) and exp not in rerun_exps:
                print(f"üü° Skipping {exp} on {branch} (cached)")
                continue
            run_benchmark(exp, cmd_template)
            copy_result(exp, branch, result_dir, result_filename, cache_dir)
    finally:
        if get_current_branch() != current:
            print(f"üîÑ Switching back to original branch: {current}")
            checkout_branch(current)


def run_comparison(config: Dict[str, Any]):
    cache_dir = Path(config["paths"]["results_cache"])
    result_dir = Path(config["paths"]["results_dir"])
    result_filename = config["paths"]["result_filename"]
    cmd_template = config["command"]

    branches = config["branches"]
    experiments = config["experiments"]
    experiment_names = [e["name"] for e in experiments]
    branch_names = [b["name"] for b in branches]

    if len(branch_names) != 2:
        print("‚ùå Exactly two branches must be specified for comparison.")
        sys.exit(1)

    # Initialize per-branch rerun experiment sets
    rerun_exps: Dict[str, Set[str]] = {b: set() for b in branch_names}

    for branch in branches:
        bname = branch["name"]
        if branch.get("rerun", False):
            rerun_exps[bname].update(experiment_names)

    for exp in experiments:
        if exp.get("rerun", False):
            for bname in branch_names:
                rerun_exps[bname].add(exp["name"])

    b1, b2 = branch_names
    print(f"üîç Preparing to compare: {b1} vs {b2}")

    process_branch(
        b1,
        experiment_names,
        rerun_exps[b1],
        cache_dir,
        result_dir,
        result_filename,
        cmd_template,
    )

    process_branch(
        b2,
        experiment_names,
        rerun_exps[b2],
        cache_dir,
        result_dir,
        result_filename,
        cmd_template,
    )

    print("\nüìä Comparing benchmark results...")
    all_passed = True
    for exp in experiment_names:
        if not compare_results(exp, b1, b2, cache_dir):
            all_passed = False

    if all_passed:
        print("\n‚úÖ All experiments matched between branches.")
        sys.exit(0)
    else:
        print("\n‚ùå Some experiments differ between branches.")
        sys.exit(1)


def main():
    ensure_clean_git_state()

    parser = argparse.ArgumentParser(
        description="Compare benchmark results between two git branches using a YAML config."
    )
    parser.add_argument(
        "--config",
        type=str,
        default=None,
        help=f"Optional path to YAML config file. Defaults to {DEFAULT_CONFIG_PATH}",
    )

    args = parser.parse_args()
    config_path = Path(args.config) if args.config else DEFAULT_CONFIG_PATH

    if not config_path.exists():
        print(f"‚ùå Config file not found: {config_path}")
        sys.exit(1)

    with open(config_path, "r") as f:
        config = yaml.safe_load(f)

    run_comparison(config)


if __name__ == "__main__":
    main()
